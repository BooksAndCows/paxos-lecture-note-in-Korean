# Multi Paxos

## 1. 멀티 팍소스의 구현

팍소스 알고리즘의 목적은 **복제로그의 생성**과 이 로그를 통해 **복제된 상태머신을 생성**하는 것 이라는 것을 Basic Paxos를 통해 배웠다. **멀티 팍소스**는 단 하나의 값을 선출하는** Basic Paxos의 여러 독립적인 사례를 묶어** 로그를 형성하는 연속된 값을 선출해 내는 방식이다. 이러한 멀티 팍소스를 구현하기 위해서는 각각의 Prepare과 Accpet 요청에 변수\(Argument\)를 추가 하면 된다. 그리고 이러한 요청은 특정 로그 항목을 선택하며 모든 서버는 모든 로그의 항목들에 대해 **서버 각자의 독립된 상태**를 갖추고 있다.

> One way to do that, is to use a collection of basic Paxos instances. One independent instance for each of the entries in the log.
>
> So to do this, we just add extra argument to each of the prepare and accept request that selects particular log entry and all of the servers keep separate state for every entry into the log.

![](/assets/Multi Paxos 1.PNG)

위 그림은 클라이언트가 서버에게 명령을 요청을 하면 발생하는 **과정**을 보여주고 있다. 첫번째로 클라이언트가 상태 머신이 실행 시켜 주었으면 하는 **명령**을 서버 중 하나의 팍소스 모듈에게 보낸다. 그럼 그 모듈은 팍소스 프로토콜을 통해 다른 서버들과 소통해 합의를 이끌어내고 클라이언트의 명령이 로그 중 하나의 항목으로 들어갈 수 있게 만들어 준다. 그 후에 로그에 들어간 명령을 상태 머신에 적용하게 되는데 이때 들어간 명령 앞에 있던 다른 명령들이 먼저 로그에 기록되고 상태 머신에 적용되기를 기다린다. 이렇게 상태 머신에 새 명령어가 적용이 되면 그 결과를 클라이언트한테 알려준다.

## 2. 멀티 팍소스를 구현할 때 고려해야 할 점들

멀티 팍소스를 구현할 때에는 어떠한 점들을 고려해야 할까. 여러가지 고려 사항들을 먼저 간단히 알아보고 각 사례에 대해 하나하나씩 자세히 알아보는 시간을 가져보자.

![](/assets/Multi Paxos 2.PNG)

먼저 클라이언트의 요청에 로그 중 **어느 항목을 사용**해야 할까 라는 점이 첫번째 고려사항이다. 로그에는 다양한 항목들이 들어 갈 수 있는 공간이 있고 이러한 공간을 어떻게 어떤 순서로 항목들을 넣어야할지 생각해 봐야 할 것이다. 그 다음 고려 사항은 **성능의 최적화**에 관한 것 이다. 전에 사용했던 Basic 팍소스의 방식을 사용하면 하나의 합의를 도출 하는데에도 오랜 시간이 걸리기 때문에 이러한 점들을 해결 하는 방안을 찾아야 할 것이다. 이러한 방안으로서는 **지도자를 선출**해 제안들의 **충돌을 최소화** 시키고 준비 **요청 단계를 최소**한으로 줄이는 방안을 사용할 것이다. 그 다음으로 생각해야 할 점은 어떻게 모든 서버가 로그를 **동일하게 일치**시킬 것 이며 서버들이 각자 가지고 있는 로그들이 선택\(Chosen\) 되어진 값인지를 **확인** 할 수 있게 만들어 줘야 할 것이다. 그 다음에는 클라이언트 프로토콜로서 **서버가 다운**이 되더라도\(Crash\) 어떻게 계속해서 작동을 해야 하는지에 대한 방안을 생각 해 볼 것이다. 마지막으로는 서버들이 추가가 되거나 제거가 되는 등 **변화**에 대해 어떻게 안전하게 대처를 해야 할 지 알아볼 것이다.

> 참조: 멀티 팍소스는 Basic 팍소스와 다르게 매우 추상적인 표현들과 구체적으로 설명 되어 있지 않다. 또한 멀티 팍소스를 실제로 적용하는 것에는 위의 여러가지 문제들을 해결 함에 있어서 다양한 방법이 있다. 아래의 설명부터는 이런 다양한 문제점들을 해결하는 방안을 쉽게 설명할 수 있도록 작성하였다.

### 2.1 로그 항목 선택

이제부터 멀티 팍소스를 구현할때 고려해야 할 첫번째 요소인 로그 항목 선택에 대해 알아보자

![](/assets/Multi Paxos 3.PNG)위 그림처럼 서버가 3개가 있다고 가정하자. 그리고 좌측 그림의 s1, s2, s3는 각각의 서버의 로그를 보여준다.  이러한 상황에서 클라이언트에서 s1에게 jmp 요청을 했다고 하자. 이때 서버 s1에 기록된 항목들은 다양한 상황에 있을 수 있는데,  서버는 어떤 항목들은 이미 **선택 완료\(Chosen\)**된 항목들 이라는 것을 알고 있을 수 있다. 예를 들면 위의 그림에서 s1옆에 두껍게 표시된 1,2,6번 항목은 이미 선택이 완료된 항목 된 곳들이다. 이렇게 서버가 어떤 항목이 선택 완료 되었는지 알 수 있는지에 대한 자세한 내용은 향후 더 나오겠지만 여기선 s1이 제안한 명령들이라 선택 완료가 되었는지 알 수 있었다고 가정하자.

s1의 3번 항목같은 경우 서버가 항목으로 **인정\(Accepted\)**한 항목이지만 다른 서버에서도 다들 합의가 완료되어 선택 완료\(Chosen\)가 되었는지는 모르는 경우이다. 물론 우리는 그림을 보고 3개의 서버 중 s1이 3번으로 cmp를 인정했고 s3또한 3번으로 cmp를 인정 함으로서 과반수를 넘었으니 선택 완료 된 것임을 알 수 있으나 서버 s1의 입장에서는 그것을 알 수 없는 상황이다.

그리고 서버 s1의 4,5번 항목엔 아직 인정해 받아들인 값이 없는 상황이지만 s2에선 4번 항목에 sub를 s3에선 5번으로 cmp를 인정한 상태임을 알 수 있다. 이러한 상황에서 새로운 요청이 들어오면 어떻게 되는지 알아보자.

처음으로 s1 서버에 요청이 들어오면, s1은 본인의 로그 번호 중 **선택 완료 되지 않은 제일 낮은 번호**를 찾는다. 이 경우에는 지금 3번이 아직 인정 된 부분이고 선택 완료가 되지 않았음으로 3번을 찾게 된다. 그리고 그 항목에 새로 들어온 값을 넣어 보려고 시도를 한다.

그럼 이쯤에서 잠시 상황 설명을 간단히 하기 위해 서버 s3이 없다고 하자. 현재  서버는 s1과 s2만 있다고 가정하자.

![](/assets/Multi Paxos 3_1.PNG)

그럼 다시 돌아와서 s1의 3번 항목에 jmp를 넣어 보려고 하지만 **이미** cmp라는 **값이 들어가 있기 때문에** 3번에 jmp를 넣는건 포기하고 3번 항목을 cmp로 선택 완료 시킬 것 이다. 우측 그림을 보면 s1이 s2에게 3번 항목으로 cmp을 요청해 s1, s2 둘다 3번을 cmp로 선택 완료 했음을 볼 수 있다.

이렇게 되면 아직까지 클라이언트의 jmp 요청이 받아들여지지 않았기 때문에 다시 처음부터 시작한다. 다시 선택 완료 되지 않은 항목을 찾는데 이번에는 3은 선택 완료 되었으니 4번을 살펴보게 된다. 이러나 이번엔 s2가 4번 항목으로 sub를 선택했으므로 또 다시 jmp를 포기하고 sub를 선택 완료 할 수 있게 진행한다.

그럼 또 한번 처음부터 시작하는데 이번에는 4번 다음인 5번 항목을 보게 된다. 이번에는 5번 항목에는 어떠한 값들도 인정\(Accepted\) 되어있지 않았기에 5번 항목에 jmp를 성공적으로 인정하게 되고 결론적으로 선택 완료를 시킨다.

이렇게 선택이 된 후에 다음번에 또 s1에 요청이 들어오면 선택 완료 되지 않은 가장 낮은 항목 번호인 7번을 보게 된다.

이 모든 과정을 정리해 보자면, 서버가 요청을 받으면 선택 완료되지 않은 가장 낮은 항목 번호부터 시작해 요청을 넣을 수 있는 곳을 찾을 때 까지 계속해서 항목 **번호를 증가시키며** 찾는다는 것이다.

![](/assets/Multi Paxos 4.PNG)

이러한 방식으로 하나의 서버는 **여러개의 클라이언트 요청**을 다룰 수 있다. 만약 특정 클라이언트가 3번에 요청을 했으면 다음 클라이언트는 4번에 요청하는 등 다른 항목 번호에 요청을 하는 한 모두 독립적으로 **병렬적으로 요청** 할 수 있다.

그러나 **상태 머신**에 이렇게 만들어진 로그를 적용을 할 때에는 **순서대로 적용**이 되어야 한다. 즉 4번 항목은 3번이 먼저 적용되기 전까진 적용 될 수 없으며 3번 항목 또한 2번이 상태머신에 먼저 적용이 된 후에 처리가 가능하다는 말이다.

### 2.2 성능 최적화

팍소스 알고리즘을 다루며 우리는 크게 두가지 문제점이 있다는 점을 배웠다.

첫번로는 서버들에 **여러개의 제안자**\(Proposer\)가 있을 경우 **충돌**\(Conflict\)이 발생되어 몇몇 제안들은 다시 시작해야 하고 심하면 루프에 빠지게 되는 경우\(Livelock\)등이 있다. 특히 클라이언트가 많으면 많을 수록 같은 항목에 요청을 하는 경우의 수가 늘어가게 되고 서버가 충돌들을 해결하느라 진행이 느려지는 경우가 발생할 수 있다.

두번째로는 한 항목에 값을 넣을 때 **매번 2번의 RPC**\(원격 프로시저 호출\)를 하게 된다. 제안자는 먼저 Prepare을 보내고나서 또 Accept를 보내야하는 번거로움이 있다.

![](/assets/Multi Paxos 5.PNG)

이러한 문제점들을 해결 하기 위해 두가지 해결 방안이 있다.

첫번째로는 모든 클라이언트의 요청을 단 하나의 서버에게만 보내고 **그 서버만이 제안자의 역할**을 하게 만드는 것 이다. 그런 역할을 하는 서버를 **리더**라고 부르기로 하자.

두번째로는 Prepare을 하는 RPC 단계를 크게 줄여 최적화를 시킬 수 있다. 이는 처음 리더가 Prepare을 할 때 모든 로그 항목들에 대해서 하는 **Prepare을 한번에 다** 하는 것이다. 그 후에는 Accept만 해주는 과정으로 일을 진행함으로서 일 처리를 2배나 빠르게 만들 수 있다.

### 2.2.1 리더 선출

리더 선출 방법에는 다양한 방법이 있지만 우리는 레슬리 렘포트\(미국의 컴퓨터 과학자\)에 의해 선택된 간단한 방식을 알아 볼 것이다. 그 방식은 아래와 같다.

* 먼저 서버 ID중 가장 높은 번호를 가진 서버가 리더가 되게 한다.

* 이런 리더를 선출하기 위해 서버들은 다른 모든 서버들에게 매 T ms 시간마다 본인의 서버 ID를 담아 신호를 보낸다. 그러면서 다른 서버들에게 받은 신호에 담겨진 서버 ID들을 확인한다.

* 만약 서버가 2T ms 시간동안 본인보다 더 높은 서버 ID 신호를 받지 못했다면 그 서버는 리더의 역할을 할 것이다. 그럼으로서 클라이언트들로 요청을 받고 Proposer와 Acceptor의 역할을 수행 할 것이다.

* 만약 서버가 리더의 역할이 되지 못했다면 클라이언트의 요청을 거절하고 클라이언트에게 리더에게 요청하기를 요구한다. 또한 그 서버는 Acceptor 의 역할만 하게 된다.

이러한 방식으로 동시에 두개의 리더가 일을 하는 것을 방지할 수 있게 되었다. 물론 리더 두개가 존재할 수는 있지만 당연히 충돌등의 이유로 효율성은 더 떨어질 것이다.

### 2.2.2 Prepare 제거

최적화의 두번째 방법으로는 RPC 단계를 줄이는 것이다. 우리는 이를 Prepare 단계를 최대한으로 없앰으로서 할 수 있다. 그럼 줄이기 전에 왜 Prepare 단계가 필요했는지 다시 복습을 해보자.

![](/assets/Multi Paxos 6.PNG)

Prepare 단계가 필요한 첫번째 이유는 **옛날 제안들\(Proposals\)을 막기 위해**서다. 두번째로는 **로그의 항목에 의해 선택된 값**들에 대해 알아내기 위해서 이다. 이런 선택된 값들이 있다면 제안하던 값은 잠시 놔두고 그 값을 계속 지지 해줘야 하기 때문이다.

Prepare을 하는 첫 번째 이유인 오래된 제안을 막는 방식을 **대처** 할 수 있는 방법으로는 각각의 항목에 사용 하는 제안 번호\(Proposal Number\)를 매번 다른 번호를 쓰는 것 보다 모든 항목에 사용하는 **제안 번호를 동일하게 **사용하게 하는 것이다. 이러한 방식으로 다음번 로그 항목에 쓸 제안 번호를 계속 설정 할 필요가 없어진다.

Prepare를 하는 두번째 이유인 로그 항목의 값에 대해 알아내는 방식은 여전히 Proposer가 물어본 항목이 받은 가장 높은 제안 번호를 반환 하지만 또한 Acceptor는 현재 받은 요청 이후의 로그들을 보고 현재의 요청 이후에 어떠한 인정된\(Accepted\) 값들이 없다면, 즉 본인이 보낸 요청한 값을 인정\(Accept\)한 것 이라면, **noMoreAccepted 라는 신호도 같이 **반환 하게 된다.

결국에 리더는 각각의 Acceptor 서버로부터 noMoreAccepted를 받는 시점이 있을 것이며, 그럼 그 Acceptor의 상태를 리더가 알고 됨으로서 더 이상 Prepare을 그 Acceptor에게 보낼 필요가 없는 것이다. 더 나아가, 이러한 noMoreAccepted 신호를 절반 이상의 서버들에게서 받으면 더이상 Prepare RPC를 할 필요가 없어진다. 그럼 이제 리더는 Accept RPC를 모든 서버에게 한번만 보내면 모든 준비는 끝이 났기때문에 리더가 요청한 값이 선택 완료가 되어진다.

이러한 현상은 리더가 변경이 될 때까지 계속 될 것이며 변경이 되면 리더의 Accept RPC가 거절 될 것이고 다시 처음부터 진행을 하게 될 것이다.

### 2.2.3 공개

마지막으로 팍소스의 문제점으로는 Acceptor들이 전체적인 로그의 상황에 대해 인식이 부족하다는 점이다. 지금의 알고리즘으로서는 모든 서버가 값을 Accept 하지 않아도** 과반수의 서버만**이 동의를 하면 선택 완료되었다고 여겨지기 때문에 완전한 값의 복사가 일어났다고 보기 힘들다. 즉 모든 서버의 로그 항목에 값들이 복사되는 방법을 찾아야 한다.

또한 지금은 어떤 값을 제안\(Propose\) 한 서버만이 Accept RPC를 통해 절반이 넘는 서버에게서 동의가 되면 그 값이 **선택 완료**된 값임을 알뿐 다른 Accept 서버들은 본인들이 갖고 있는 값이 선택 완료 된 값인지 알 수가 없다. 이러한 점을 보안해 Propose한 서버 이외의 서버들도 선택 완료된 항목을 알 수 있게 만들어 그 항목들을 최대한 빨리 상태 머신에 적용 할 수 있게 도와줘야 할 것이다.

이러한 문제들은 4가지 단계를 통해 해결 할 수 있다.

![](/assets/Multi Paxos 7.PNG)

첫번째 단계로는 과반수에 의해 Accept가 반환이 되어도 **계속해서 Accept RPC**를 보내는 것이다. 일단 과반수가 Accept를 했으므로 로그에 선택 완료로 표기하고 상태 머신에 적용한 뒤 클라이언트에게 결과를 보여줄 수 있다. 그러나 동시에 이러한 과정 **뒤에서** 계속해서 서버들에게 Accept RPC를 보내어 과반수 뿐만 아니라 모든 서버들에게로 부터 Accept 반응을 받아낸다. 이렇게 함으로서 **성능은 유지**하면서 거의 대부분의 서버들에 값이 복사가 되어 있게 만들 수 있다. 그러나 여전히 어떤 서버들은 다운이 되면서 값들이 전부 복제가 되지 않은 현상이 있을 수 있으므로 더 보안을 해야 한다.

두번째 단계로는 각각의 서버에서 어떤 로그의 항목이 **선택 완료**가 되었는지 **추적**을 할 필요가 있다. 이러한 것을 하기 위해 만약 서버가 어떤 항목이 선택 완료가 되었다는 점을 알게 된다면, 서버는 그 항목의 인정된 제안 번호\(Accepted Proposal Number\)의 값을 **독특한 값으로 설정**한다. 이러한 독특한 값들은 보통 어떤 제안 번호보다 가장 큰 값들로 선택하며 여기선 그 값을 무한대라고 가정하자. 무한대로 정한 이유는 서버가 이미 Accept된 값을 덮어 씌우는 경우는 새로 들어온 제안 번호가 더 큰 경우에만 덮어 씌우기 때문에 더 큰 숫자가 없기하기 위해 무한대로 정한 것 이다.

또한 각자의 서버는 **아직 선택 되지 않은 첫 항목의 번호\(firstUnchosenIndex\)**를 가지고 있다. 즉 제안 번호가 무한대로 설정 되어 있지 않은 로그의 항목 번호이다.

![](/assets/Multi Paxos 8.PNG)

세번째 단계로는 Proposer 서버가 Acceptor 서버들에게 선택 완료된 것으로 알려진 항목들에 대한 **정보**를 알려주는 것이다. Proposer 서버는 이런 정보를 Accept RPC를 보낼때 어떤것이 선택된 항목인지에 대한 정보를 같이 껴서 보내는 방식으로 알려준다. 이때 보내는 정보에는 **firstUnchosenIndex**가 들어가는데 Acceptor는 이 번호를 보고 이 번호 밑에 항목들은 Proposer에 의해 선택 완료가 되었다는 것을 알 수가 있게 된다. 그리고 이 번호를 통해 본인의 로그에서 어떤것들이 선택 완료 되었는지 결정할 수 있다.

이 단계에 대한 예시로 위 그림의 로그 부분을 봐보자. 위에 로그는 Accept RPC를 받기 전 로그이고 그 밑에 그림은 받고 난 후 이다. 그림에서 로그의 항목에 들어있는 번호와 기호는 그 항목에 쓰인 제안 번호이지 항목에 들어간 값이나 명령어가 아님을 알아두자.

다시 그림을 보면 먼저 1, 2, 3, 5번들은 이미 선택 완료된 항목임을 무한대 기호를 통해 알 수 있다. 4번과 6번은 다른 제안 번호가 적혀있는 것을 통해 아직 선택 완료 된 것인지 알 수 없음을 알 수 있다.

이제 Accept 요청이 Proposer로 부터 왔다고 가정하자. 그 요청에는 **제안 번호 3.4**와 **아직 선택되지 않은 첫 항목 번호로 7번**이 왔다. 즉 이말은 Proposer 입장에서는 1번부터 6번까지는 이미 다 선택 완료가 되었다는 뜻이다. 이러한 메시지를 받은 Acceptor는 제안 번호 3.4를 가지고 7번 항목 밑의 항목까지 제안 번호를 비교를 한다. 그리고 만약에 비교한 제안 번호와 같은 번호를 가지고 있는 항목이 있다면 그 항목을 선택 완료 되었다고 판단해 번호를 무한대로 바꾼다. 

이러한 과정이 가능한 것은 Acceptor의 입장에서 Acceptor가 알고 있는 점을 고려해 보면 알 수 있다. 먼저 제안 번호\(여기서는 3.4\)가 같다는 것은 본인에게 제안을 보낸 **동일한** Proposer 서버에서 온 요청이라는 점을 알 수 있다. 또한 제안 번호가 바뀌지 않고 동일하다는 것은 아직까지 Proposer가 바뀌지 않았음을 뜻 함으로 Proposer에서 선택된 값이라는 것을 확신 할 수 있다. 그리고 이러한 판단을 통해 Acceptor는 항목의 제안 번호를 무한대로 바꾸게 된다.

